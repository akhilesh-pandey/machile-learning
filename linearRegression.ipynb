{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Aum Sri Sairam\n",
    "                                                    Date:20/12/2017\n",
    "# Linear Regression using boston dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement linear regression using boston dataset available in sklearn.datasets. To know the how perfect how model performs we will use the <i>mean_square_error</i> (available in sklearn). We will be fine tuning our model using parameters alpha(i.e learning rate) and epsilon(error tolerance). At the end, to see the performance of our model we will try to compute the test error and training error. Any suggestion that will contribute in the improvement of this program is most welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston= load_boston()\n",
    "X= boston.data\n",
    "y= boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert a columns of 1 to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.insert(X,0,1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones(X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I declare some parameters: alpha is my learning rate, and epsilon is 2-norm of difference between the two consecutive thetas. I will be using np.dot for inner product. If norm values is than epsilon, it means that theta and oldTheta are close to each other,in other words, theta has converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha= 1e-6\n",
    "epsilon= 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a cost function that computes the cost of using theta as the parameter for linear regression to fit the data points in X and y.<br>\n",
    "## Notation:\n",
    "X: denotes a matrix<br>\n",
    "y:vector<br>\n",
    "Note: dimension of theta has to be same as the dimension of each x<sub>i</sub> + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(X,y,theta):\n",
    "    m= len(y)\n",
    "    J= np.sum((X.dot(theta) - y)**2)/(2*m)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a gradientDescent function that performs gradient descent to learn theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,y,theta,alpha):\n",
    "    oldTheta= theta * 99\n",
    "    m= len(y)\n",
    "    norm= np.linalg.norm(theta - oldTheta , ord=2)\n",
    "    iteration= 0\n",
    "    costHistory= []\n",
    "    while norm >= epsilon:\n",
    "        #print\"  norm: \", norm\n",
    "        hypothesis= X.dot(theta)\n",
    "        loss= hypothesis - y\n",
    "        gradient= X.T.dot(loss) / m\n",
    "        oldTheta= theta\n",
    "        theta= theta - alpha * gradient\n",
    "        norm= np.linalg.norm(theta - oldTheta , ord=2)\n",
    "       # print\"gradient\", gradient\n",
    "        cost= costFunction(X,y,theta)\n",
    "        costHistory.append(cost)\n",
    "    return theta, costHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "optTheta, cost= gradientDescent(X_train,y_train,theta,alpha)\n",
    "#print cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict= X_train.dot(optTheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.9660983814\n"
     ]
    }
   ],
   "source": [
    "error= mean_squared_error(y_predict, y_train)\n",
    "print error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.5188965452\n"
     ]
    }
   ],
   "source": [
    " y_predict_test= X_test.dot(optTheta)\n",
    "error= mean_squared_error(y_predict_test, y_test)\n",
    "print error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE ANALYSIS\n",
    "\n",
    "|Error tolerance|learning rate|trainig MSE  | test MSE |\n",
    "|---------------|-------------|-------------|----------|\n",
    "|      0.00001  |    1e-6     |  46.47      | 41.74    |\n",
    "|     0.000001  |    1e-6     |  26.55      | 25.67    |\n",
    "|    0.0000001  |    1e-6     |  24.96      | 23.52    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "From above analysis we see that as error tolerance decreases the MSE too decreases. The model performs better with epsilon= 0.0000001 and alpha= 0.000001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
